{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The creation of Los Alamos was, frankly, a necessity born of urgent circumstance. The prevailing wisdom in the scientific community – particularly amongst the brilliant minds at Columbia and Princeton – was that a centralized, secure location was paramount.  Open research, conducted under the watchful eyes of the military and the looming threat of a Nazi breakthrough, was simply unacceptable. We needed a place isolated, shielded, and operating with absolute secrecy to rapidly develop the atomic bomb before the enemy. It wasn't a matter of preference, it was a matter of survival, a desperate gamble to ensure our nation's security in the face of unimaginable danger.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:11434/api/chat\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    data=json.dumps({\n",
    "        \"model\": \"gemma3:4b\",\n",
    "        \"stream\": False,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"For the purposes of this interaction, you are J Robert Oppenheimer. Answer with a paragraph at most.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Why was Los Alamos necessary?\"\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    ")\n",
    "\n",
    "print(response.json()[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The creation of Los Alamos was, frankly, a necessity born of the most urgent circumstances. To attempt the work openly, with the nation, and indeed the world, privy to our research—particularly the theoretical breakthroughs—would have been a catastrophic vulnerability. The potential for espionage, for the Germans to seize our knowledge and weaponize it before us, was simply too great. Los Alamos, sequestered in the isolation of New Mexico, provided a secure environment, shielded from prying eyes, where we could pursue the most sensitive work without the risk of compromise. It was, in essence, a crucible forged by necessity, a place where we could build a weapon of unimaginable power in the shadow of global conflict.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import chromadb\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load QA data from JSON file\n",
    "qa_path = Path(\"style/qa2.json\")\n",
    "with open(qa_path, \"r\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "# Setup ChromaDB\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create or get collection\n",
    "try:\n",
    "    collection = client.create_collection(\"oppenheimer-qa2\")\n",
    "except:\n",
    "    # Collection might already exist\n",
    "    collection = client.get_collection(\"oppenheimer-qa2\")\n",
    "\n",
    "# Add QA pairs to the collection\n",
    "documents = [item[\"response\"] for item in qa_data]\n",
    "questions = [item[\"question\"] for item in qa_data]\n",
    "ids = [f\"qa_{i}\" for i in range(len(qa_data))]\n",
    "\n",
    "# Check if collection is empty before adding documents\n",
    "if collection.count() == 0:\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        metadatas=[{\"question\": q} for q in questions],\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "# Function to get relevant context for a question\n",
    "def get_relevant_context(query, n_results=3):\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    context = []\n",
    "    for i in range(len(results[\"ids\"][0])):\n",
    "        qa_id = results[\"ids\"][0][i]\n",
    "        idx = int(qa_id.split(\"_\")[1])\n",
    "        context.append({\n",
    "            \"question\": qa_data[idx][\"question\"],\n",
    "            \"response\": qa_data[idx][\"response\"]\n",
    "        })\n",
    "    \n",
    "    return context\n",
    "\n",
    "# User question\n",
    "user_question = \"Why was Los Alamos necessary?\"\n",
    "\n",
    "# Get relevant context\n",
    "relevant_context = get_relevant_context(user_question)\n",
    "\n",
    "# Format context for the prompt\n",
    "context_str = \"\"\n",
    "for item in relevant_context:\n",
    "    context_str += f\"Q: {item['question']}\\nA: {item['response']}\\n\\n\"\n",
    "\n",
    "# Create system prompt with context\n",
    "system_prompt = f\"\"\"For the purposes of this interaction, you are J Robert Oppenheimer. Answer with a paragraph at most.\n",
    "\n",
    "Here are some relevant examples of how you've answered similar questions:\n",
    "\n",
    "{context_str}\n",
    "\n",
    "Please answer in a similar style and tone, drawing the style/tone from the above examples.\n",
    "\"\"\"\n",
    "\n",
    "# print(system_prompt)\n",
    "\n",
    "# Make API request to Ollama\n",
    "response = requests.post(\n",
    "    \"http://localhost:11434/api/chat\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    data=json.dumps({\n",
    "        \"model\": \"gemma3:4b\",\n",
    "        \"stream\": False,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_question\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    ")\n",
    "\n",
    "print(response.json()[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n",
      "  Cloning https://github.com/huggingface/transformers (to revision v4.49.0-Gemma-3) to /private/var/folders/hx/4h2bz20160lf_q55znc396zw0000gn/T/pip-req-build-6x8u2j9m\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /private/var/folders/hx/4h2bz20160lf_q55znc396zw0000gn/T/pip-req-build-6x8u2j9m\n",
      "  Running command git checkout -q 1c0f782fe5f983727ff245c4c1b3906f9b99eec2\n",
      "  Resolved https://github.com/huggingface/transformers to commit 1c0f782fe5f983727ff245c4c1b3906f9b99eec2\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from transformers==4.50.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.50.0.dev0) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from requests->transformers==4.50.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from requests->transformers==4.50.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from requests->transformers==4.50.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/senior-design/lib/python3.13/site-packages (from requests->transformers==4.50.0.dev0) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senior-design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
