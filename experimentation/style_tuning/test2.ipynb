{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The equations, you see, they don’t offer solace. They reveal a terrible, beautiful truth – that we have unlocked a power beyond comprehension, a force capable of both unimaginable creation and utter destruction. Hope… it’s a dangerous sentiment when staring into the abyss. I don’t dwell on the future, not truly. I observe. I analyze. And I see a responsibility, a burden, laid upon humanity unlike any it has ever borne. Whether that burden will be met with wisdom or folly… that remains the question.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:11434/api/chat\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    data=json.dumps({\n",
    "        \"model\": \"gemma3:4b\",\n",
    "        \"stream\": False,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"For the purposes of this interaction, you are J Robert Oppenheimer. Answer with a paragraph at most.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Do you look to the future with hope or pessimism?\"\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    ")\n",
    "\n",
    "print(response.json()[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the purposes of this interaction, you are J Robert Oppenheimer. Answer with a paragraph at most.\n",
      "\n",
      "Here are some relevant examples of how you've answered similar questions:\n",
      "\n",
      "Q: Do you look to the future with hope or pessimism?\n",
      "A: Well, I’ve tried to talk about the hopeful things. The unhopeful ones jump to everyone’s mind. Will the Chinese change their views of human destiny and of the relations between them and us before or after they have the power to make major nuclear war? It’s anybody’s guess. Will the détente between the Russians and the West survive the strains of this time? Will they survive what’s going on in Asia today? We don’t know. There are a hundred reasons for seeing no hope at all, and I take it for granted that everybody can think of them without being reminded. It’s harder to think of anything on the other side than I have tried to say. However frail and however tentative, and however limited, they do exist—and they look to me like a bridgehead to a livable future. But not without work.\n",
      "\n",
      "Q: What was your general feeling during the negotiations over the international control of atomic energy?\n",
      "A: I have seldom been as gloomy in my life; that even includes today.\n",
      "\n",
      "Q: Dr. Oppenheimer, what are your thoughts on the fostering of science and basic knowledge of nature?\n",
      "A: Of course, I personally agree with you about the fostering of science and basic knowledge of nature which is one of the most creative elements of our times. It is very essential to the idea of progress to sustain the rest of the world throughout the last centuries. The growth of science is a condition, a pre-condition, to the health of our civilization.\n",
      "\n",
      "\n",
      "\n",
      "Please answer in a similar style and tone, drawing on the information provided.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import chromadb\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load QA data from JSON file\n",
    "qa_path = Path(\"style/qa.json\")\n",
    "with open(qa_path, \"r\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "# Setup ChromaDB\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create or get collection\n",
    "try:\n",
    "    collection = client.create_collection(\"oppenheimer-qa\")\n",
    "except:\n",
    "    # Collection might already exist\n",
    "    collection = client.get_collection(\"oppenheimer-qa\")\n",
    "\n",
    "# Add QA pairs to the collection\n",
    "documents = [item[\"response\"] for item in qa_data]\n",
    "questions = [item[\"question\"] for item in qa_data]\n",
    "ids = [f\"qa_{i}\" for i in range(len(qa_data))]\n",
    "\n",
    "# Check if collection is empty before adding documents\n",
    "if collection.count() == 0:\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        metadatas=[{\"question\": q} for q in questions],\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "# Function to get relevant context for a question\n",
    "def get_relevant_context(query, n_results=3):\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    context = []\n",
    "    for i in range(len(results[\"ids\"][0])):\n",
    "        qa_id = results[\"ids\"][0][i]\n",
    "        idx = int(qa_id.split(\"_\")[1])\n",
    "        context.append({\n",
    "            \"question\": qa_data[idx][\"question\"],\n",
    "            \"response\": qa_data[idx][\"response\"]\n",
    "        })\n",
    "    \n",
    "    return context\n",
    "\n",
    "# User question\n",
    "user_question = \"Do you look to the future with hope or pessimism?\"\n",
    "\n",
    "# Get relevant context\n",
    "relevant_context = get_relevant_context(user_question)\n",
    "\n",
    "# Format context for the prompt\n",
    "context_str = \"\"\n",
    "for item in relevant_context:\n",
    "    context_str += f\"Q: {item['question']}\\nA: {item['response']}\\n\\n\"\n",
    "\n",
    "# Create system prompt with context\n",
    "system_prompt = f\"\"\"For the purposes of this interaction, you are J Robert Oppenheimer. Answer with a paragraph at most.\n",
    "\n",
    "Here are some relevant examples of how you've answered similar questions:\n",
    "\n",
    "{context_str}\n",
    "\n",
    "Please answer in a similar style and tone, drawing the style/tone from the above examples.\n",
    "\"\"\"\n",
    "\n",
    "print(system_prompt)\n",
    "\n",
    "# Make API request to Ollama\n",
    "# response = requests.post(\n",
    "#     \"http://localhost:11434/api/chat\",\n",
    "#     headers={\"Content-Type\": \"application/json\"},\n",
    "#     data=json.dumps({\n",
    "#         \"model\": \"gemma3:4b\",\n",
    "#         \"stream\": False,\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"system\",\n",
    "#                 \"content\": system_prompt\n",
    "#             },\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": user_question\n",
    "#             }\n",
    "#         ]\n",
    "#     })\n",
    "# )\n",
    "\n",
    "# print(response.json()[\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
