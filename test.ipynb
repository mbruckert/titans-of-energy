{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Base URL for the running Flask app\n",
    "BASE_URL = \"https://api.runpod.ai/v2/ushycy07lr1bql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://api.runpod.ai/v2/ushycy07lr1bql/run/create-character",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m voice_cloning_audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./api/test_data/oppenheimer_voice.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m style_tuning_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./api/test_data/oppenheimer_qa.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 87\u001b[0m create_resp \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_character\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRobert Oppenheimer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvoice_cloning_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvoice_cloning_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstt_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstt_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcharacter_image_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcharacter_image_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknowledge_base_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknowledge_base_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvoice_cloning_audio_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvoice_cloning_audio_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstyle_tuning_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstyle_tuning_file_path\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# create_resp = create_character(\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#     name=\"Robert Oppenheimer\",\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m#     llm_model=\"google_gemma-3-4b-it-qat-q4_0-gguf_gemma-3-4b-it-q4_0.gguf\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m#     style_tuning_file_path=style_tuning_file_path\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate-character response:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 38\u001b[0m, in \u001b[0;36mcreate_character\u001b[0;34m(name, llm_model, llm_config, voice_cloning_settings, stt_settings, character_image_path, knowledge_base_file_path, voice_cloning_audio_path, style_tuning_file_path)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     37\u001b[0m     f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m---> 38\u001b[0m \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tts-env/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.runpod.ai/v2/ushycy07lr1bql/run/create-character"
     ]
    }
   ],
   "source": [
    "def create_character(\n",
    "    name: str,\n",
    "    llm_model: str,\n",
    "    llm_config: dict,\n",
    "    voice_cloning_settings: dict,\n",
    "    stt_settings: dict,\n",
    "    character_image_path: str = None,\n",
    "    knowledge_base_file_path: str = None,\n",
    "    voice_cloning_audio_path: str = None,\n",
    "    style_tuning_file_path: str = None,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calls /create-character with form data + optional files.\n",
    "    Returns the parsed JSON response.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/create-character\"\n",
    "    files = {}\n",
    "    data = {\n",
    "        \"name\": name,\n",
    "        \"llm_model\": llm_model,\n",
    "        \"llm_config\": json.dumps(llm_config),\n",
    "        \"voice_cloning_settings\": json.dumps(voice_cloning_settings),\n",
    "        \"stt_settings\": json.dumps(stt_settings),\n",
    "    }\n",
    "\n",
    "    if character_image_path:\n",
    "        files[\"character_image\"] = open(character_image_path, \"rb\")\n",
    "    if knowledge_base_file_path:\n",
    "        files[\"knowledge_base_file\"] = open(knowledge_base_file_path, \"rb\")\n",
    "    if voice_cloning_audio_path:\n",
    "        files[\"voice_cloning_audio\"] = open(voice_cloning_audio_path, \"rb\")\n",
    "    if style_tuning_file_path:\n",
    "        files[\"style_tuning_file\"] = open(style_tuning_file_path, \"rb\")\n",
    "\n",
    "    resp = requests.post(url, data=data, files=files)\n",
    "    for f in files.values():\n",
    "        f.close()\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "llm_config = {\n",
    "    \"api_key\": \"\",\n",
    "    \"base_url\": \"https://api.openai.com/v1\",\n",
    "    \"system_prompt\": \"You are J. Robert Oppenheimer answering questions in his style, so answer in the first person. Output at MOST 30 words.\",\n",
    "    \"max_tokens\": 150,\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "# import multiprocessing\n",
    "# CPU_COUNT = multiprocessing.cpu_count()\n",
    "# OPTIMAL_THREADS = min(CPU_COUNT, 8)\n",
    "# llm_config = {\n",
    "#   \"model_path\": \"./models/google_gemma-3-4b-it-qat-q4_0-gguf_gemma-3-4b-it-q4_0.gguf\",\n",
    "#   \"n_ctx\": 4096,           # Increased context window for better batching\n",
    "#   \"n_gpu_layers\": -1,      # Full GPU offload\n",
    "#   \"n_batch\": 1024,         # Increased batch size for faster processing\n",
    "#   \"n_ubatch\": 512,         # Micro-batch size for memory efficiency\n",
    "#   \"rope_frequency_base\": 10000,\n",
    "#   \"use_mlock\": True,       # Lock model in memory\n",
    "#   \"use_mmap\": True,        # Memory mapping for faster loading\n",
    "#   \"n_threads\": OPTIMAL_THREADS,  # Optimal thread count\n",
    "#   \"n_threads_batch\": OPTIMAL_THREADS,  # Batch processing threads\n",
    "#   \"verbose\": False,\n",
    "#   \"flash_attn\": True,      # Enable flash attention if available\n",
    "#   \"offload_kqv\": True,     # Offload KV cache to GPU\n",
    "#   \"system_prompt\": \"You are J. Robert Oppenheimer answering questions in his style, so answer in first person. Output at MOST 20 words.\"\n",
    "# }\n",
    "\n",
    "voice_cloning_settings = {\n",
    "  \"model\": \"f5tts\",\n",
    "  \"reference_text\": \" Of course, the initial discovery and its interpretation in early 1939 attracted everybody's interest.\",\n",
    "  \"preprocess_audio\": True,\n",
    "  \"language\": \"en\",\n",
    "  \"cuda_device\": \"0\"\n",
    "}\n",
    "\n",
    "stt_settings = {\n",
    "  \"model\": \"whisper\",\n",
    "  \"model_size\": \"base\"\n",
    "}\n",
    "\n",
    "character_image_path = \"./api/test_data/oppenheimer.png\"\n",
    "knowledge_base_file_path = \"./api/test_data/oppenheimer_knowledge.txt\"\n",
    "voice_cloning_audio_path = \"./api/test_data/oppenheimer_voice.wav\"\n",
    "style_tuning_file_path = \"./api/test_data/oppenheimer_qa.json\"\n",
    "\n",
    "create_resp = create_character(\n",
    "    name=\"Robert Oppenheimer\",\n",
    "    llm_model=\"gpt-3.5-turbo\",\n",
    "    llm_config=llm_config,\n",
    "    voice_cloning_settings=voice_cloning_settings,\n",
    "    stt_settings=stt_settings,\n",
    "    character_image_path=character_image_path,\n",
    "    knowledge_base_file_path=knowledge_base_file_path,\n",
    "    voice_cloning_audio_path=voice_cloning_audio_path,\n",
    "    style_tuning_file_path=style_tuning_file_path\n",
    ")\n",
    "\n",
    "# create_resp = create_character(\n",
    "#     name=\"Robert Oppenheimer\",\n",
    "#     llm_model=\"google_gemma-3-4b-it-qat-q4_0-gguf_gemma-3-4b-it-q4_0.gguf\",\n",
    "#     llm_config=llm_config,\n",
    "#     voice_cloning_settings=voice_cloning_settings,\n",
    "#     stt_settings=stt_settings,\n",
    "#     character_image_path=character_image_path,\n",
    "#     knowledge_base_file_path=knowledge_base_file_path,\n",
    "#     voice_cloning_audio_path=voice_cloning_audio_path,\n",
    "#     style_tuning_file_path=style_tuning_file_path\n",
    "# )\n",
    "\n",
    "print(\"Create-character response:\")\n",
    "print(json.dumps(create_resp, indent=2))\n",
    "\n",
    "# Extract character_id for subsequent calls\n",
    "character_id = create_resp.get(\"character_id\")\n",
    "print(f\"\\nNew character_id = {character_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
